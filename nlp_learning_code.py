# -*- coding: utf-8 -*-
"""NLP learning code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QsRyi-01A_zbKhWZ0OAGFnrGLo8Sz5jS
"""

pip install textacy

import pandas as pd
from google.colab import files

data1= files.upload()

data2= files.upload()

data3= files.upload()

import pandas as pd
import numpy as np
import re
data3=pd.read_csv("2014.csv",encoding='latin1',low_memory=True)
data2=pd.read_csv("2012-2013.csv",encoding='latin1',low_memory=True)
data1=pd.read_csv("2007-2011.csv",encoding='latin1',low_memory=True)
df=pd.concat([data1,data2,data3],axis=0).reset_index()

#Split data and delete date formate
def sub(string, pattern, replace):
    return re.sub(pattern, replace, string)          
data1.loc[0:5000, "loan_desc"] = data1.loc[0:5000, "desc"].fillna("")# dealing with the np.nan entries, replacing them with an empty string
data1.loc[0:5000, "loan_desc"] = data1.loc[0:5000, "loan_desc"].apply(sub, args=(r'(\d{2}/\d{1,2}/\d{1,2})','',))
text=""
for i in range(0,5000):
    text += data1.loc[i, "loan_desc"]
'''
df.loc[:, "loan_desc"] = df.loc[:, "desc"].fillna("")# dealing with the np.nan entries, replacing them with an empty string
df.loc[:, "loan_desc"] = df.loc[:, "loan_desc"].apply(sub, args=(r'(\d{2}/\d{1,2}/\d{1,2})','',))
text=""
for i in range(len(df)):
    text += df.loc[i, "loan_desc"]
'''

import spacy
import textacy.extract
# Parse the document with spaCy
nlp = spacy.load('en_core_web_sm')
doc = nlp(text)

# Extract noun chunks that appear more than 15 times
noun_chunks = textacy.extract.noun_chunks(doc, min_freq=15)

# Convert noun chunks to lowercase strings
noun_chunks = map(str, noun_chunks)
noun_chunks = map(str.lower, noun_chunks)

# Print out any nouns that are at least 2 words long
for noun_chunk in set(noun_chunks):
    if len(noun_chunk.split(" ")) > 1:
        print(noun_chunk)

# Parse the document with spaCy
doc = nlp(text)

# Extract semi-structured statements
statements = textacy.extract.semistructured_statements(doc, "I")


for statement in statements:
    subject, verb, fact = statement
    print(f" - {fact}")